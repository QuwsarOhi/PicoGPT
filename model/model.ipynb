{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import inspect\n",
    "import os, io, pickle\n",
    "import copy\n",
    "\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<?>': 0} {0: '<?>'}\n",
      "[84, 104, 105, 115, 32, 105, 115, 32, 97, 32, 115, 101, 110, 116, 101, 110, 99, 101]\n",
      "This is a sentence\n",
      "<?>This is a sentence\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer():\n",
    "    '''\n",
    "    Very simple tokenizer that convers integer to ASCII\n",
    "    [0, 7] can be saved for special tokens if needed as they are not viewable\n",
    "    '''\n",
    "    __slots__ = ['vocab_size', 'special_enc', 'special_dec']\n",
    "    \n",
    "    def __init__(self, specials: List[str] = ['<?>']) -> None:\n",
    "        self.vocab_size = 128\n",
    "        self.special_enc = dict((c, i) for i, c in enumerate(specials))\n",
    "        self.special_dec = dict((i, c) for i, c in enumerate(specials))\n",
    "        print(self.special_enc, self.special_dec)\n",
    "            \n",
    "    def encode(self, x: List[str]) -> List[int]:\n",
    "        ret = []\n",
    "        for xx in x:\n",
    "            if xx in self.special_enc:\n",
    "                ret.append(self.special_enc[xx])\n",
    "            elif 7 < ord(xx) < self.vocab_size:\n",
    "                ret.append(ord(xx))\n",
    "            else:\n",
    "                ret.append(0)\n",
    "        return ret\n",
    "    \n",
    "    def decode(self, x: List[int]) -> List[str]:\n",
    "        ret = []\n",
    "        for xx in x:\n",
    "            if xx in self.special_dec:\n",
    "                ret.append(self.special_dec[xx])\n",
    "            elif 7 < xx < self.vocab_size:\n",
    "                ret.append(chr(xx))\n",
    "            else:\n",
    "                ret.append(self.special_dec[0])\n",
    "        return ret\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "print(tokenizer.encode(\"This is a sentence\"))\n",
    "print(''.join(tokenizer.decode(tokenizer.encode(\"This is a sentence\"))))\n",
    "print(''.join(tokenizer.decode([0] + tokenizer.encode(\"This is a sentence\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # block_size: int = 1024\n",
    "    # # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    # vocab_size: int = 50304 \n",
    "    # n_layer: int = 12\n",
    "    # n_head: int = 12\n",
    "    # n_embd: int = 768\n",
    "    # dropout: float = 0.0\n",
    "    # # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "    # bias: bool = True \n",
    "\n",
    "    block_size: int = 32\n",
    "    # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    vocab_size: int = 128 \n",
    "    n_layer: int = 2\n",
    "    n_head: int = 2\n",
    "    n_embd: int = 64\n",
    "    dropout: float = 0.0\n",
    "    # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "    bias: bool = True \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 64])\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # linear is usually multiplied by 4\n",
    "        # here we have 2 for efficiency\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 2 * config.n_embd, bias=config.bias)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(2 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "mlp = MLP(GPTConfig)\n",
    "print(mlp(torch.rand(2, 2, 64)).shape)\n",
    "del mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 64])\n"
     ]
    }
   ],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        # efficient attention using Flash Attention CUDA kernels\n",
    "        # y.shape (B, nh, T, hs)\n",
    "        y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, \n",
    "                                                             dropout_p=self.dropout if self.training else 0, \n",
    "                                                             is_causal=True)\n",
    "        \n",
    "        # re-assemble all head outputs side by side\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) \n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "    \n",
    "catt = CausalSelfAttention(GPTConfig)\n",
    "print(catt(torch.rand(2, 2, 64)).shape)\n",
    "del catt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 64])\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "    \n",
    "block = Block(GPTConfig)\n",
    "print(block(torch.rand(2, 2, 64)).shape)\n",
    "del block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.08M\n",
      "torch.Size([2, 1, 128]) None\n"
     ]
    }
   ],
   "source": [
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "        \n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        # https://paperswithcode.com/method/weight-tying\n",
    "        self.transformer.wte.weight = self.lm_head.weight \n",
    "\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/((2 * config.n_layer)**0.5))\n",
    "        \n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        # token embeddings of shape (b, t, n_embd)\n",
    "        tok_emb = self.transformer.wte(idx) \n",
    "        # position embeddings of shape (t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos) \n",
    "        # add position embeddings\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        \n",
    "        # propagating through transformers\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def crop_block_size(self, block_size):\n",
    "        # model surgery to decrease the block size if necessary\n",
    "        # e.g. we may load the GPT2 pretrained model checkpoint (block size 1024)\n",
    "        # but want to use a smaller block size for some smaller, simpler model\n",
    "        assert block_size <= self.config.block_size\n",
    "        self.config.block_size = block_size\n",
    "        self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:block_size])\n",
    "        for block in self.transformer.h:\n",
    "            if hasattr(block.attn, 'bias'):\n",
    "                block.attn.bias = block.attn.bias[:,:,:block_size,:block_size]\n",
    "\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
    "        # start with all of the candidate parameters\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        # filter out those that do not require grad\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == 'cuda'\n",
    "        extra_args = dict(fused=True) if use_fused else dict()\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits, _ = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx\n",
    "    \n",
    "\n",
    "gpt = GPT(GPTConfig)\n",
    "#gpt = torch.compile(gpt)\n",
    "out, loss = gpt(torch.ones((2, 8), dtype=torch.long))\n",
    "print(out.shape, loss)\n",
    "del gpt, out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "\n",
    "class TrainConfig:\n",
    "    \n",
    "    batch_size: int = 8\n",
    "    dtype: str = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "    device: str = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datapath = os.path.join(\n",
    "    '..', \n",
    "    'dataset',\n",
    "    'tinyshakespeare.txt'\n",
    ")\n",
    "\n",
    "with open(datapath, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - GPTConfig.block_size, (TrainConfig.batch_size,))\n",
    "    x = torch.stack([data[i:i+GPTConfig.block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+GPTConfig.block_size+1] for i in ix])\n",
    "    x, y = x.to(TrainConfig.device), y.to(TrainConfig.device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32]) torch.Size([8, 32])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch('train')\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.08M\n"
     ]
    }
   ],
   "source": [
    "model = GPT(GPTConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32, 128]) tensor(4.8475, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out, loss = model(x, y)\n",
    "print(out.shape, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f14989828d0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "warmup_iters = 2000\n",
    "learning_rate = 6e-4\n",
    "lr_decay_iters = 600000\n",
    "min_lr = 6e-5\n",
    "\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return min_lr + coeff * (learning_rate - min_lr)\n",
    "\n",
    "\n",
    "x = list(range(100000))\n",
    "y = [get_lr(xx) for xx in x]\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 10, with 75,776 parameters\n",
      "num non-decayed parameter tensors: 18, with 1,536 parameters\n",
      "using fused AdamW: False\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "device = 'cpu'\n",
    "\n",
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/16797#issuecomment-633423219\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "\n",
    "def train_fn(model: nn.Module,\n",
    "             epoch: int,\n",
    "             optimizer: torch.optim.Optimizer,\n",
    "             savepath: str = None,\n",
    "             device='cpu'):\n",
    "\n",
    "    best_weight = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    train_phases = ['train', 'val']\n",
    "    losses = {phase: [] for phase in train_phases}\n",
    "\n",
    "    if savepath and os.path.exists(savepath):\n",
    "        # Try loading the model and weight\n",
    "        try:\n",
    "            with open(savepath, 'rb') as filehandler:\n",
    "                prev_train = CPU_Unpickler(filehandler).load()\n",
    "                best_weight = prev_train['best_weight']\n",
    "                model.load_state_dict(best_weight, strict=False)\n",
    "                losses = prev_train['losses']\n",
    "                best_loss = prev_train['best_loss']\n",
    "                optimizer = prev_train['optimizer'] \n",
    "                print(f\"Loaded model with loss: {best_loss:0.4f}\")\n",
    "        except:\n",
    "            print(f\"Could not load from path: {savepath}\")\n",
    "\n",
    "\n",
    "    for e in range(epoch):\n",
    "        for phase in train_phases:\n",
    "            is_training = (phase == 'train')\n",
    "            model.train() if is_training else model.eval()\n",
    "\n",
    "            loss, dats = 0., 0.,\n",
    "            tqdm_data = tqdm(data[phase])\n",
    "\n",
    "            for _ in range(1000):\n",
    "                x, y = get_batch(phase)\n",
    "                #x, y = x.to(device), y.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    _, batch_loss = model(x)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        batch_loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if scheduler: scheduler.step()\n",
    "\n",
    "                # Stats\n",
    "                dats += x.size(0)\n",
    "                loss += batch_loss.item() * x.size(0)\n",
    "                corrects += torch.sum(classes == y.data)\n",
    "                tqdm_data.set_description(f\"Epoch {e+1} [{phase.upper()}]: Loss: {loss/dats:.4f}\")\n",
    "\n",
    "            epoch_loss = loss / dats\n",
    "            epoch_acc = corrects.double() / dats\n",
    "            losses[phase].append(epoch_loss)\n",
    "\n",
    "            if phase == \"val\" and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_weight = copy.deepcopy(model.state_dict())\n",
    "                if savepath:\n",
    "                    with open(savepath, 'wb') as filehandler:\n",
    "                        pickle.dump({\n",
    "                            'best_weight': best_weight,\n",
    "                            'best_loss': best_loss,\n",
    "                            'losses': losses,\n",
    "                            'optimizer': optimizer\n",
    "                        }, filehandler)\n",
    "                print(f\"Best loss found: {best_loss:3.4f}\")\n",
    "\n",
    "    print(f'Best loss: {best_loss:3.4f}')\n",
    "    model.load_state_dict(best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ohi/Downloads/TinyLM/model/model.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_fn(model, \n\u001b[1;32m      <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m          \u001b[39m1000\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m          optimizer,\n\u001b[1;32m      <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m          os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m'\u001b[39;49m\u001b[39m..\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlogs\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlog.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m          \u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/ohi/Downloads/TinyLM/model/model.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load from path: \u001b[39m\u001b[39m{\u001b[39;00msavepath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Gathering all dataset phases\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m dataset_sizes \u001b[39m=\u001b[39m {train_phase : \u001b[39mlen\u001b[39;49m(data[train_phase]\u001b[39m.\u001b[39;49mdataset) \\\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m                  \u001b[39mfor\u001b[39;49;00m train_phase \u001b[39min\u001b[39;49;00m train_phases}\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mfor\u001b[39;00m phase \u001b[39min\u001b[39;00m train_phases:\n",
      "\u001b[1;32m/home/ohi/Downloads/TinyLM/model/model.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load from path: \u001b[39m\u001b[39m{\u001b[39;00msavepath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Gathering all dataset phases\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m dataset_sizes \u001b[39m=\u001b[39m {train_phase : \u001b[39mlen\u001b[39m(data[train_phase]\u001b[39m.\u001b[39mdataset) \\\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m                  \u001b[39mfor\u001b[39;00m train_phase \u001b[39min\u001b[39;00m train_phases}\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[1;32m     <a href='vscode-notebook-cell://192.168.1.70:8080/home/ohi/Downloads/TinyLM/model/model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mfor\u001b[39;00m phase \u001b[39min\u001b[39;00m train_phases:\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "train_fn(model, \n",
    "         1000,\n",
    "         optimizer,\n",
    "         os.path.join('..', 'logs', 'log.pkl'),\n",
    "         'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
