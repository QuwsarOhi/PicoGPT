{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import inspect\n",
    "import os, io, pickle\n",
    "import copy\n",
    "import math\n",
    "\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # block_size: int = 1024\n",
    "    # # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    # vocab_size: int = 50304 \n",
    "    # n_layer: int = 12\n",
    "    # n_head: int = 12\n",
    "    # n_embd: int = 768\n",
    "    # dropout: float = 0.0\n",
    "    # # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "    # bias: bool = True \n",
    "\n",
    "    block_size: int = 128\n",
    "    # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    vocab_size: int = 128 \n",
    "    n_layer: int = 2\n",
    "    n_head: int = 2\n",
    "    n_embd: int = 64\n",
    "    dropout: float = 0.0\n",
    "    # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "    bias: bool = True \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    batch_size: int = 8\n",
    "    dtype: str = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "    device: str = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "    warmup_iters = 2000\n",
    "    learning_rate = 6e-4\n",
    "    lr_decay_iters = 600000\n",
    "    min_lr = 6e-5    \n",
    "    weight_decay = 1e-1\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.95\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<?>': 0} {0: '<?>'}\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer():\n",
    "    '''\n",
    "    Very simple tokenizer that convers integer to ASCII\n",
    "    [0, 7] can be saved for special tokens if needed as they are not viewable\n",
    "    '''\n",
    "    __slots__ = ['vocab_size', 'special_enc', 'special_dec']\n",
    "    \n",
    "    def __init__(self, specials: List[str] = ['<?>']) -> None:\n",
    "        self.vocab_size = 128\n",
    "        self.special_enc = dict((c, i) for i, c in enumerate(specials))\n",
    "        self.special_dec = dict((i, c) for i, c in enumerate(specials))\n",
    "        print(self.special_enc, self.special_dec)\n",
    "            \n",
    "    def encode(self, x: List[str]) -> List[int]:\n",
    "        ret = []\n",
    "        for xx in x:\n",
    "            if xx in self.special_enc:\n",
    "                ret.append(self.special_enc[xx])\n",
    "            elif 7 < ord(xx) < self.vocab_size:\n",
    "                ret.append(ord(xx))\n",
    "            else:\n",
    "                ret.append(0)\n",
    "        return ret\n",
    "    \n",
    "    def decode(self, x: List[int]) -> List[str]:\n",
    "        ret = []\n",
    "        for xx in x:\n",
    "            if xx in self.special_dec:\n",
    "                ret.append(self.special_dec[xx])\n",
    "            elif 7 < xx < self.vocab_size:\n",
    "                ret.append(chr(xx))\n",
    "            else:\n",
    "                ret.append(self.special_dec[0])\n",
    "        return ret\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "# print(tokenizer.encode(\"This is a sentence\"))\n",
    "# print(''.join(tokenizer.decode(tokenizer.encode(\"This is a sentence\"))))\n",
    "# print(''.join(tokenizer.decode([0] + tokenizer.encode(\"This is a sentence\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # linear is usually multiplied by 4\n",
    "        # here we have 2 for efficiency\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 2 * config.n_embd, bias=config.bias)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(2 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "# mlp = MLP(GPTConfig)\n",
    "# print(mlp(torch.rand(2, 2, 64)).shape)\n",
    "# del mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        # efficient attention using Flash Attention CUDA kernels\n",
    "        # y.shape (B, nh, T, hs)\n",
    "        y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, \n",
    "                                                             dropout_p=self.dropout if self.training else 0, \n",
    "                                                             is_causal=True)\n",
    "        \n",
    "        # re-assemble all head outputs side by side\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) \n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "    \n",
    "# catt = CausalSelfAttention(GPTConfig)\n",
    "# print(catt(torch.rand(2, 2, 64)).shape)\n",
    "# del catt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "    \n",
    "# block = Block(GPTConfig)\n",
    "# print(block(torch.rand(2, 2, 64)).shape)\n",
    "# del block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerger(nn.Module):\n",
    "    # https://github.com/lucidrains/vit-pytorch/blob/5578ac472faf3903d4739ba783f3875b77177e57/vit_pytorch/vit_with_patch_merger.py#L4\n",
    "\n",
    "    def __init__(self, dim, num_tokens_out):\n",
    "        super().__init__()\n",
    "        self.scale = dim ** -0.5\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.queries = nn.Parameter(torch.randn(num_tokens_out, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        # queries.shape: [BS, M, DIM]\n",
    "        # x.shape: [BS, T, DIM]\n",
    "        # out: [M, DIM] x [DIM, T] = [M, T]\n",
    "        sim = torch.matmul(self.queries, x.transpose(-1, -2)) * self.scale\n",
    "        # att.shape: [BS, M, T]\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        # [M, T] x [T, DIM]\n",
    "        return torch.matmul(attn, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "        \n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        # https://paperswithcode.com/method/weight-tying\n",
    "        self.transformer.wte.weight = self.lm_head.weight \n",
    "        # self.patchmerger = PatchMerger(config.n_embd, 16)\n",
    "        # self.patchextend = PatchMerger(config.n_embd, 32)\n",
    "\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/((2 * config.n_layer)**0.5))\n",
    "        \n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        # token embeddings of shape (b, t, n_embd)\n",
    "        tok_emb = self.transformer.wte(idx) \n",
    "        # position embeddings of shape (t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos) \n",
    "        # add position embeddings\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        \n",
    "        # propagating through transformers\n",
    "        for i, block in enumerate(self.transformer.h):\n",
    "            x = block(x)\n",
    "            # if i == 0: \n",
    "            #     x = self.patchmerger(x)\n",
    "            # elif i == self.config.n_layer-2:\n",
    "            #     x = self.patchextend(x)\n",
    "                \n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def crop_block_size(self, block_size):\n",
    "        # model surgery to decrease the block size if necessary\n",
    "        # e.g. we may load the GPT2 pretrained model checkpoint (block size 1024)\n",
    "        # but want to use a smaller block size for some smaller, simpler model\n",
    "        assert block_size <= self.config.block_size\n",
    "        self.config.block_size = block_size\n",
    "        self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:block_size])\n",
    "        for block in self.transformer.h:\n",
    "            if hasattr(block.attn, 'bias'):\n",
    "                block.attn.bias = block.attn.bias[:,:,:block_size,:block_size]\n",
    "\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
    "        # start with all of the candidate parameters\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        # filter out those that do not require grad\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == 'cuda'\n",
    "        extra_args = dict(fused=True) if use_fused else dict()\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits, _ = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx\n",
    "    \n",
    "\n",
    "# gpt = GPT(GPTConfig)\n",
    "# #gpt = torch.compile(gpt)\n",
    "# out, loss = gpt(torch.ones((2, 8), dtype=torch.long))\n",
    "# print(out.shape, loss)\n",
    "# del gpt, out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datapath = os.path.join(\n",
    "    '..', \n",
    "    'dataset',\n",
    "    'tinyshakespeare.txt'\n",
    ")\n",
    "\n",
    "with open(datapath, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - GPTConfig.block_size, (TrainConfig.batch_size,))\n",
    "    x = torch.stack([data[i:i+GPTConfig.block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+GPTConfig.block_size+1] for i in ix])\n",
    "    x, y = x.to(TrainConfig.device), y.to(TrainConfig.device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.08M\n"
     ]
    }
   ],
   "source": [
    "model = GPT(GPTConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = get_batch('train')\n",
    "# print(x.shape, y.shape)\n",
    "# out, loss = model(x, y)\n",
    "# print(out.shape, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < TrainConfig.warmup_iters:\n",
    "        return TrainConfig.learning_rate * it / TrainConfig.warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > TrainConfig.lr_decay_iters:\n",
    "        return TrainConfig.min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - TrainConfig.warmup_iters) / (TrainConfig.lr_decay_iters - TrainConfig.warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return TrainConfig.min_lr + coeff * (TrainConfig.learning_rate - TrainConfig.min_lr)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# x = list(range(100000))\n",
    "# y = [get_lr(xx) for xx in x]\n",
    "# plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 10, with 81,920 parameters\n",
      "num non-decayed parameter tensors: 18, with 1,536 parameters\n",
      "using fused AdamW: False\n"
     ]
    }
   ],
   "source": [
    "optimizer = model.configure_optimizers(TrainConfig.weight_decay, \n",
    "                                       TrainConfig.learning_rate, \n",
    "                                       (TrainConfig.beta1, TrainConfig.beta2), \n",
    "                                       TrainConfig.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/16797#issuecomment-633423219\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "\n",
    "def train_fn(model: nn.Module,\n",
    "             epoch: int,\n",
    "             optimizer: torch.optim.Optimizer,\n",
    "             savepath: str = None,\n",
    "             device='cpu'):\n",
    "\n",
    "    best_weight = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    train_phases = ['train', 'val']\n",
    "    losses = {phase: [] for phase in train_phases}\n",
    "\n",
    "    if savepath and os.path.exists(savepath):\n",
    "        # Try loading the model and weight\n",
    "        try:\n",
    "            with open(savepath, 'rb') as filehandler:\n",
    "                prev_train = CPU_Unpickler(filehandler).load()\n",
    "                best_weight = prev_train['best_weight']\n",
    "                model.load_state_dict(best_weight, strict=False)\n",
    "                losses = prev_train['losses']\n",
    "                best_loss = prev_train['best_loss']\n",
    "                optimizer = prev_train['optimizer'] \n",
    "                print(f\"Loaded model with loss: {best_loss:0.4f}\")\n",
    "        except:\n",
    "            print(f\"Could not load from path: {savepath}\")\n",
    "\n",
    "\n",
    "    for e in range(epoch):\n",
    "        for phase in train_phases:\n",
    "            is_training = (phase == 'train')\n",
    "            model.train() if is_training else model.eval()\n",
    "            loss, dats = 0., 0.,\n",
    "            tqdm_prog = tqdm(range(1000))\n",
    "\n",
    "            for _ in tqdm_prog:\n",
    "                x, y = get_batch(phase)\n",
    "                #x, y = x.to(device), y.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    _, batch_loss = model(x, y)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        batch_loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Stats\n",
    "                dats += x.size(0)\n",
    "                loss += batch_loss.item() * x.size(0)\n",
    "                tqdm_prog.set_description(f\"Epoch {e+1} [{phase.upper()}]: Loss: {loss/dats:.4f}\")\n",
    "\n",
    "            epoch_loss = loss / dats\n",
    "            losses[phase].append(epoch_loss)\n",
    "\n",
    "            if phase == \"val\" and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_weight = copy.deepcopy(model.state_dict())\n",
    "                if savepath:\n",
    "                    with open(savepath, 'wb') as filehandler:\n",
    "                        pickle.dump({\n",
    "                            'best_weight': best_weight,\n",
    "                            'best_loss': best_loss,\n",
    "                            'losses': losses,\n",
    "                            'optimizer': optimizer\n",
    "                        }, filehandler)\n",
    "                print(f\"Best loss found: {best_loss:3.4f}\")\n",
    "\n",
    "    print(f'Best loss: {best_loss:3.4f}')\n",
    "    model.load_state_dict(best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea218abcd2434c6c8c3de962266a0259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51eb607200ae445d8e090fc6244a2625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 2.4265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e30508d91c4194ac7423f0ccbe95aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c9b18a0839448789f55bc4e23351fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 2.2558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cbe1d831f64b29b1b678754e9fd873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf1629bca9b44c19f5174f2f4dfc7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 2.1065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eeca0a37f5d40d69872c5376e08516c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b10fdcb3ee34a2ea6c269d7963bec52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.9907\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efe168bfe7e4646bbabef05ef0bd505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfb6875ec784146bfcda25abd4b9d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.9423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208160ab7f89416f9f66df65e4a3ccc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a804d35ee7a243758aa1637e7f84eaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.9043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d8c2f667b44e9caa612a1006655221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7beb9525f94f479a81e9676467ef001f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.8597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406eda4d60804a6b91c76b69a12ba39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395498254d4c4fe199d99c9aa4563a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.8528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da76262872c4a3fa3ee584acc72332e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b37ebe0d114e50bd1762f789ceef99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.8327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8049202b66458f9f7943db8dcd4e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6eaa35a983c4b3c934e1f28251e3c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.8239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4addd9be9a46718cb6e540a5398ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6260e8c97f5a4f8d907694eca68142c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.8046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3897039301458597a655ba911bceb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b0b6d06f9d432d819579c71b0afde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.7898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34161f0f71234bfabb6139bdc986ed4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319413b5a24b4c6ea55e7fb78cc6516d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58852009b99481ca509b0832172fc79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedb3e6749a84ea39f90a0d28e936f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4c64363122421e9f50d77a485606d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6854a21dcb43458f9e0ee68a1fa7921a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.7766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663ae323635448629e06572cabcf8c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9e1dacb259410aba0e2e20f81f62ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.7723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a84ee404e1406b8f8e600d3d9181e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ee5e1b3f4f4b86bec9eb53ccddb1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.7697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4fd9161a4241a4973754b2c584f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45daff0488b4929b232ef893a24a781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.7674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7340e7309914dae9d385c4036a37cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9dbd98d528f4fff8ab97eee75518cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.7494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af249be4a7d14fa8929b2076ef2a0051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4560e6c8886e4b9c94d909d01a0685d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366950d7629c4562881b2467ccdad3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d7bdc7427f4862ba753ea659c24f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss found: 1.7466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc029b7670754c458de54eb22076f9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706dc0ff06a44d9a979b44bfda359a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 1.7466\n"
     ]
    }
   ],
   "source": [
    "train_fn(model, \n",
    "         22,\n",
    "         optimizer,\n",
    "         os.path.join('..', 'logs', 'log.pkl'),\n",
    "         'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with loss: 1.7466\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "savepath = os.path.join(\n",
    "    \"..\", \"logs\", \"log.pkl\"\n",
    ")\n",
    "\n",
    "def plot_graph(savepath):\n",
    "    with open(savepath, 'rb') as filehandler:\n",
    "        prev_train = CPU_Unpickler(filehandler).load()\n",
    "        # best_weight = prev_train['best_weight']\n",
    "        # model.load_state_dict(best_weight)\n",
    "        losses = prev_train['losses']\n",
    "        best_loss = prev_train['best_loss']\n",
    "        print(f\"Loaded model with loss: {best_loss:0.4f}\")\n",
    "\n",
    "    epochs = range(1, len(losses['train'])+1)\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color=color)\n",
    "    ax1.plot(epochs, losses['train'], color=color, linestyle='dashed')\n",
    "    ax1.plot(epochs, losses['val'], color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plot_graph(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"he is armement?\\nYour us and rungs give his your shall 'sword.\\n\\nWAULT:\\nWhat to-rumpy and lives\\nTon Embaled t\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(tokenizer.encode(\"he is a\"), dtype=torch.int).unsqueeze(0)\n",
    "model.eval()\n",
    "# model.generate(self, idx, max_new_tokens, temperature=1.0, top_k=None)\n",
    "''.join(tokenizer.decode(model.generate(x, max_new_tokens=100).detach()[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchtext\n",
    "# torchtext.datasets.WikiText103(root=os.path.join('..', 'wikitext'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
